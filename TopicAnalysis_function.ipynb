{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b9faec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: how does climate change impact agriculture and health\n",
      "Query: how does climate change impact agriculture and health\n",
      "Predicted Topics: ['Health', 'Environment', 'Food']\n"
     ]
    }
   ],
   "source": [
    "# # Import necessary libraries\n",
    "# import torch\n",
    "# from transformers import BertTokenizer, BertForSequenceClassification\n",
    "# import numpy as np\n",
    "# import re\n",
    "\n",
    "\n",
    "# # Reload the saved model and tokenizer\n",
    "# tokenizer = BertTokenizer.from_pretrained(\"./topic_model\")\n",
    "# model = BertForSequenceClassification.from_pretrained(\"./topic_model\")\n",
    "\n",
    "# # Define topic_labels (ensure it matches training)\n",
    "# topic_labels = {\n",
    "#     \"Health\": 0,\n",
    "#     \"Environment\": 1,\n",
    "#     \"Technology\": 2,\n",
    "#     \"Economy\": 3,\n",
    "#     \"Entertainment\": 4,\n",
    "#     \"Sports\": 5,\n",
    "#     \"Politics\": 6,\n",
    "#     \"Education\": 7,\n",
    "#     \"Travel\": 8,\n",
    "#     \"Food\": 9,\n",
    "#     # Add other topics...\n",
    "# }\n",
    "# label_to_topic = {idx: topic for topic, idx in topic_labels.items()}  # Reverse mapping for decoding\n",
    "\n",
    "# # Define the prediction function\n",
    "\n",
    "# def predict_multi_topics(query, model, tokenizer, topic_labels, percentile=0.8):\n",
    "#     \"\"\"Predict multiple topics for a given query based on a percentile threshold.\"\"\"\n",
    "#     # Identify the device\n",
    "#     device = torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "#     model = model.to(device)\n",
    "\n",
    "#     # Tokenize and move to device\n",
    "#     encoding = tokenizer(\n",
    "#         query,\n",
    "#         max_length=128,\n",
    "#         padding=\"max_length\",\n",
    "#         truncation=True,\n",
    "#         return_tensors=\"pt\",\n",
    "#     )\n",
    "#     input_ids = encoding[\"input_ids\"].to(device)\n",
    "#     attention_mask = encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "#     # Get logits\n",
    "#     model.eval()\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(input_ids, attention_mask=attention_mask)\n",
    "#         logits = outputs.logits.squeeze(0).cpu().numpy()  # Move logits to CPU for processing\n",
    "\n",
    "#     # Calculate dynamic threshold using percentile\n",
    "#     threshold = np.percentile(logits, percentile * 100)\n",
    "\n",
    "#     # Identify topics above threshold\n",
    "#     topics = [\n",
    "#         label_to_topic[idx] for idx, score in enumerate(logits) if score > threshold\n",
    "#     ]\n",
    "#     return topics\n",
    "\n",
    "# # Preprocess the query\n",
    "# def preprocess_query(query):\n",
    "#     query = query.lower()\n",
    "#     query = re.sub(r\"[^\\w\\s]\", \"\", query)  # Remove punctuation\n",
    "#     query = re.sub(r\"\\d+\", \"\", query)  # Remove numbers\n",
    "#     return query.strip()\n",
    "\n",
    "# # Example Usage\n",
    "# query = input(\"Enter your query: \")\n",
    "# query = preprocess_query(query)\n",
    "# predicted_topics = predict_multi_topics(query, model, tokenizer, topic_labels, percentile=0.7)\n",
    "\n",
    "# print(f\"Query: {query}\")\n",
    "# print(f\"Predicted Topics: {predicted_topics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d91a2dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query: soccer\n",
      "Query: soccer\n",
      "Predicted Topic: Sports\n"
     ]
    }
   ],
   "source": [
    "# query = input(\"Enter your query: \")\n",
    "\n",
    "# # Predict the topic\n",
    "# predicted_topic = predict_topic(query, model, tokenizer, topic_labels)\n",
    "# print(f\"Query: {query}\")\n",
    "# print(f\"Predicted Topic: {predicted_topic}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60b949ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-Topic Classifier - Enter your query below (type 'exit' to quit):\n",
      "Enter your query: How does global warming impact crop production?\n",
      "Query: How does global warming impact crop production?\n",
      "Predicted Topics:\n",
      "  - Environment (Score: 0.60)\n",
      "  - Food (Score: 0.22)\n",
      "Enter your query: How does air pollution affect respiratory diseases?\n",
      "Query: How does air pollution affect respiratory diseases?\n",
      "Predicted Topics:\n",
      "  - Environment (Score: 0.58)\n",
      "  - Health (Score: 0.41)\n",
      "Enter your query: How is AI being used in diagnosing diseases?\n",
      "Query: How is AI being used in diagnosing diseases?\n",
      "Predicted Topics:\n",
      "  - Technology (Score: 0.81)\n",
      "Enter your query: What are the political implications of cryptocurrency regulations?\n",
      "Query: What are the political implications of cryptocurrency regulations?\n",
      "Predicted Topics:\n",
      "  - Politics (Score: 0.57)\n",
      "  - Technology (Score: 0.32)\n",
      "Enter your query: How is technology used in sports analytics?\n",
      "Query: How is technology used in sports analytics?\n",
      "Predicted Topics:\n",
      "  - Sports (Score: 0.57)\n",
      "  - Technology (Score: 0.41)\n",
      "Enter your query: How do government policies affect access to education?\n",
      "Query: How do government policies affect access to education?\n",
      "Predicted Topics:\n",
      "  - Education (Score: 0.93)\n",
      "Enter your query: How is virtual reality changing the entertainment industry?\n",
      "Query: How is virtual reality changing the entertainment industry?\n",
      "Predicted Topics:\n",
      "  - Technology (Score: 0.69)\n",
      "  - Entertainment (Score: 0.30)\n",
      "Enter your query: What are the latest trends in streaming platforms?\n",
      "Query: What are the latest trends in streaming platforms?\n",
      "Predicted Topics:\n",
      "  - Technology (Score: 0.98)\n",
      "Enter your query: What is the connection between diet and mental health?\n",
      "Query: What is the connection between diet and mental health?\n",
      "Predicted Topics:\n",
      "  - Health (Score: 0.71)\n",
      "Enter your query: What are the effects of global warming?\n",
      "Query: What are the effects of global warming?\n",
      "Predicted Topics:\n",
      "  - Environment (Score: 0.88)\n",
      "Enter your query: Health benefits of swimming?\n",
      "Query: Health benefits of swimming?\n",
      "Predicted Topics:\n",
      "  - Health (Score: 0.57)\n",
      "  - Sports (Score: 0.40)\n",
      "Enter your query: exit\n",
      "Exiting the classifier. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the zero-shot classification pipeline\n",
    "pipe = pipeline(\"zero-shot-classification\", model=\"MoritzLaurer/bge-m3-zeroshot-v2.0\")\n",
    "\n",
    "# Define the topics\n",
    "topics = [\n",
    "    \"Health\",\n",
    "    \"Environment\",\n",
    "    \"Technology\",\n",
    "    \"Economy\",\n",
    "    \"Entertainment\",\n",
    "    \"Sports\",\n",
    "    \"Politics\",\n",
    "    \"Education\",\n",
    "    \"Travel\",\n",
    "    \"Food\",\n",
    "]\n",
    "\n",
    "# Define the hypothesis template\n",
    "hypothesis_template = \"This query is about {}.\"\n",
    "\n",
    "def classify_multi_topics(query, pipe, topics, threshold=0.3):\n",
    "    \"\"\"\n",
    "    Classify a query into multiple topics based on a confidence threshold.\n",
    "\n",
    "    Args:\n",
    "    - query: The input query.\n",
    "    - pipe: The Hugging Face zero-shot classification pipeline.\n",
    "    - topics: List of predefined topics.\n",
    "    - threshold: Confidence score threshold for multi-topic classification.\n",
    "\n",
    "    Returns:\n",
    "    - List of topics with scores above the threshold.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Perform zero-shot classification\n",
    "        output = pipe(query, topics, hypothesis_template=hypothesis_template)\n",
    "        \n",
    "        # Extract labels and scores\n",
    "        labels = output[\"labels\"]\n",
    "        scores = output[\"scores\"]\n",
    "        \n",
    "        # Filter topics based on the threshold\n",
    "        multi_topics = [\n",
    "            {\"topic\": label, \"score\": score}\n",
    "            for label, score in zip(labels, scores)\n",
    "            if score > threshold\n",
    "        ]\n",
    "        \n",
    "        # Sort by score (optional, descending)\n",
    "        multi_topics = sorted(multi_topics, key=lambda x: x[\"score\"], reverse=True)\n",
    "        \n",
    "        print(f\"Query: {query}\")\n",
    "        print(f\"Predicted Topics:\")\n",
    "        for t in multi_topics:\n",
    "            print(f\"  - {t['topic']} (Score: {t['score']:.2f})\")\n",
    "        \n",
    "        return multi_topics\n",
    "    except Exception as e:\n",
    "        print(f\"Error during classification: {e}\")\n",
    "        return []\n",
    "\n",
    "# Interactive loop for user input\n",
    "print(\"Multi-Topic Classifier - Enter your query below (type 'exit' to quit):\")\n",
    "while True:\n",
    "    query = input(\"Enter your query: \")\n",
    "    if query.lower() == \"exit\":\n",
    "        print(\"Exiting the classifier. Goodbye!\")\n",
    "        break\n",
    "    classify_multi_topics(query, pipe, topics, threshold=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df32d3e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
